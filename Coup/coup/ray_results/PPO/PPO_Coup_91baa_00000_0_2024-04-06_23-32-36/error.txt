Failure # 1 (occurred at 2024-04-06_23-33-42)
[36mray::PPO.train()[39m (pid=27456, ip=127.0.0.1, actor_id=1a3a993327e2461a92a39a0a01000000, repr=PPO)
  File "python\ray\_raylet.pyx", line 1889, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1830, in ray._raylet.execute_task.function_executor
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\function_manager.py", line 724, in actor_method_executor
    return method(__ray_actor, *args, **kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\tune\trainable\trainable.py", line 334, in train
    raise skipped from exception_cause(skipped)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\tune\trainable\trainable.py", line 331, in train
    result = self.step()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\algorithm.py", line 849, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\algorithm.py", line 3194, in _run_one_training_iteration
    results = self.training_step()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 410, in training_step
    return self._training_step_old_and_hybrid_api_stacks()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 518, in _training_step_old_and_hybrid_api_stacks
    train_results = train_one_step(self, train_batch)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\execution\train_ops.py", line 56, in train_one_step
    info = do_minibatch_sgd(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\utils\sgd.py", line 129, in do_minibatch_sgd
    local_worker.learn_on_batch(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\rollout_worker.py", line 815, in learn_on_batch
    info_out[pid] = policy.learn_on_batch(batch)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\utils\threading.py", line 24, in wrapper
    return func(self, *a, **k)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\torch_policy_v2.py", line 712, in learn_on_batch
    grads, fetches = self.compute_gradients(postprocessed_batch)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\utils\threading.py", line 24, in wrapper
    return func(self, *a, **k)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\torch_policy_v2.py", line 908, in compute_gradients
    pad_batch_to_sequences_of_same_size(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\rnn_sequencing.py", line 155, in pad_batch_to_sequences_of_same_size
    feature_sequences, initial_states, seq_lens = chop_into_sequences(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\rnn_sequencing.py", line 410, in chop_into_sequences
    assert i == len(f), f
AssertionError: [[1 1 1 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 1 1]
 ...
 [1 1 1 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [1 1 1 ... 0 0 0]]
