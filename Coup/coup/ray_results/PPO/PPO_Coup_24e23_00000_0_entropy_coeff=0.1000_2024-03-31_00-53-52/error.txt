Failure # 1 (occurred at 2024-03-31_00-54-08)
The actor died because of an error raised in its creation task, [36mray::PPO.__init__()[39m (pid=20752, ip=127.0.0.1, actor_id=2be54d6825f7f416d62ef96101000000, repr=PPO)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\worker_set.py", line 229, in _setup
    self.add_workers(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\worker_set.py", line 682, in add_workers
    raise result.get()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\utils\actor_manager.py", line 497, in _fetch_result
    result = ray.get(r)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\worker.py", line 2667, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\worker.py", line 866, in get_objects
    raise value
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=12740, ip=127.0.0.1, actor_id=d28675f101b4e5be80f0b63b01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000014AF586F190>)
  File "python\ray\_raylet.pyx", line 1889, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1830, in ray._raylet.execute_task.function_executor
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\function_manager.py", line 724, in actor_method_executor
    return method(__ray_actor, *args, **kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\rollout_worker.py", line 535, in __init__
    self._update_policy_map(policy_dict=self.policy_dict)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\rollout_worker.py", line 1743, in _update_policy_map
    self._build_policy_map(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\rollout_worker.py", line 1854, in _build_policy_map
    new_policy = create_policy_for_framework(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\utils\policy.py", line 141, in create_policy_for_framework
    return policy_class(observation_space, action_space, merged_config)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\ppo\ppo_torch_policy.py", line 49, in __init__
    TorchPolicyV2.__init__(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\torch_policy_v2.py", line 94, in __init__
    model, dist_class = self._init_model_and_dist_class()
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\policy\torch_policy_v2.py", line 512, in _init_model_and_dist_class
    model = ModelCatalog.get_model_v2(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\models\catalog.py", line 747, in get_model_v2
    raise e
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\models\catalog.py", line 721, in get_model_v2
    instance = model_cls(
  File "C:\Users\josep\Documents\Coup-RL\Coup\coup\train_ppo_shared.py", line 138, in __init__
    self.fcnet = TorchFC(obs_space.spaces['observations'], action_space, num_outputs, model_config, name)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\models\torch\fcnet.py", line 58, in __init__
    SlimFC(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\models\torch\misc.py", line 281, in __init__
    linear = nn.Linear(in_size, out_size, bias=use_bias)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\torch\nn\modules\linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

During handling of the above exception, another exception occurred:

[36mray::PPO.__init__()[39m (pid=20752, ip=127.0.0.1, actor_id=2be54d6825f7f416d62ef96101000000, repr=PPO)
  File "python\ray\_raylet.pyx", line 1883, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1984, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1889, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1830, in ray._raylet.execute_task.function_executor
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\_private\function_manager.py", line 724, in actor_method_executor
    return method(__ray_actor, *args, **kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\algorithm.py", line 533, in __init__
    super().__init__(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\tune\trainable\trainable.py", line 161, in __init__
    self.setup(copy.deepcopy(self.config))
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\algorithms\algorithm.py", line 631, in setup
    self.workers = WorkerSet(
  File "C:\Users\josep\Documents\Coup-RL\env\lib\site-packages\ray\rllib\evaluation\worker_set.py", line 181, in __init__
    raise e.args[0].args[2]
TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
