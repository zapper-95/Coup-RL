{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 13.61, "episode_media": {}, "episodes_this_iter": 200, "policy_reward_min": {"random": -2.0, "player_2": -2.0, "player_1": -2.0}, "policy_reward_max": {"random": 2.0, "player_2": 2.0, "player_1": 2.0}, "policy_reward_mean": {"random": -0.04950495049504951, "player_2": 0.07291666666666667, "player_1": 0.029411764705882353}, "custom_metrics": {}, "hist_stats": {"episode_lengths": [10, 17, 11, 16, 7, 14, 13, 15, 16, 20, 12, 11, 19, 13, 9, 15, 20, 5, 10, 6, 17, 19, 11, 26, 19, 18, 21, 15, 19, 13, 6, 9, 17, 11, 7, 16, 18, 15, 12, 5, 12, 14, 10, 7, 10, 19, 22, 7, 23, 15, 9, 19, 14, 7, 17, 12, 12, 13, 9, 20, 12, 14, 13, 10, 13, 12, 16, 9, 18, 12, 10, 16, 13, 13, 6, 22, 16, 13, 12, 17, 24, 14, 4, 15, 4, 9, 4, 8, 12, 15, 7, 10, 17, 21, 9, 7, 13, 16, 11, 13, 12, 8, 12, 15, 16, 26, 8, 15, 25, 14, 20, 13, 43, 12, 15, 13, 7, 17, 13, 13, 7, 7, 7, 16, 18, 14, 17, 11, 17, 9, 14, 19, 12, 23, 6, 6, 15, 10, 14, 11, 16, 13, 14, 14, 15, 19, 12, 12, 13, 14, 21, 11, 8, 10, 15, 40, 9, 14, 18, 15, 19, 11, 22, 14, 7, 16, 10, 15, 16, 13, 14, 12, 12, 11, 14, 12, 11, 6, 17, 9, 13, 17, 9, 15, 15, 16, 14, 11, 9, 16, 16, 5, 18, 18, 14, 6, 16, 12, 12, 12], "policy_random_reward": [1.0, 2.0, -2.0, -2.0, -1.0, -1.0, 1.0, -2.0, 2.0, -1.0, 1.0, -1.0, 2.0, -1.0, -1.0, 1.0, -2.0, -2.0, 2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -1.0, -1.0, 1.0, -2.0, -2.0, 2.0, -2.0, -1.0, 1.0, 2.0, 1.0, -1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -1.0, 1.0, -2.0, -1.0, 1.0, -2.0, 2.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0, -2.0, 1.0, 2.0, -2.0, 2.0, 2.0, 2.0, -1.0, 1.0, 2.0, -2.0, -1.0, 1.0, 2.0, -2.0, 2.0, -1.0, 2.0, 2.0, -2.0, 2.0, 2.0, -2.0, 2.0, -2.0, 1.0, -1.0, -1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 2.0, -2.0, 1.0, 1.0, -1.0, 1.0, -2.0, 2.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, 2.0, 1.0, -1.0, 2.0, -1.0, 1.0, -2.0, 2.0, -2.0, 2.0, 1.0, 1.0, -1.0, -1.0, -2.0, -2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -1.0, -2.0, 2.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, -1.0, -1.0, -2.0, -1.0, -2.0, 2.0, -1.0, 1.0, -1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -1.0, 1.0, -2.0, 2.0, 2.0, 2.0, -1.0, -1.0, -2.0, 1.0, -1.0, -2.0, -1.0, 2.0, -2.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -2.0, 2.0, 2.0], "policy_player_2_reward": [-1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, 2.0, 2.0, 2.0, -2.0, 2.0, 2.0, 2.0, -2.0, -2.0, 1.0, 1.0, 1.0, -1.0, 2.0, 1.0, 1.0, 1.0, -2.0, -2.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, 2.0, 1.0, -2.0, 2.0, 1.0, -2.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, -2.0, -1.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, 1.0, -1.0, 2.0, 2.0, -1.0, 1.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, 2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -2.0, 2.0, 2.0, -2.0, -2.0, -2.0, 1.0, 2.0, 2.0, 1.0, 2.0, -1.0, 1.0, 2.0, 2.0, -1.0], "policy_player_1_reward": [2.0, -2.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -2.0, 2.0, -1.0, -1.0, 1.0, 2.0, 1.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, -2.0, 1.0, 2.0, 2.0, -2.0, 2.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -2.0, 2.0, -1.0, -1.0, -2.0, -1.0, 2.0, 1.0, -2.0, 1.0, -1.0, 1.0, 2.0, -2.0, 2.0, -2.0, -2.0, 2.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, -2.0, 2.0, 2.0, -2.0, -1.0, -1.0, 1.0, 1.0, 2.0, 2.0, -1.0, 1.0, -2.0, 2.0, -2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -2.0, 1.0, -2.0, 1.0, -1.0, 1.0, 2.0, 2.0, 1.0, -2.0, -1.0, -1.0, 1.0, 1.0, 1.0, -2.0, -2.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8528903618565263, "mean_inference_ms": 1.2679307210330775, "mean_action_processing_ms": 0.19415837516755347, "mean_env_wait_ms": 0.12285663611887568, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.024296290007912728, "ViewRequirementAgentConnector_ms": 0.33207269070255585}, "player_1_winrate": 0.5196078431372549, "player_2_winrate": 0.53125, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {}, "episode_media": {}, "info": {"learner": {"player_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.80025510226979, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9349756771442936, "policy_loss": -0.03313263040834892, "vf_loss": 1.964279822508494, "vf_explained_var": 0.05079613678595599, "kl": 0.019142446561276377, "entropy": 1.6248547406757579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 121.47058823529412, "num_grad_updates_lifetime": 255.5, "diff_num_grad_updates_vs_sampler_policy": 254.5}, "player_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9540618809560937, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8906151780237754, "policy_loss": -0.03458518575450095, "vf_loss": 1.9219390744964282, "vf_explained_var": 0.06444158790012201, "kl": 0.016306492005187297, "entropy": 1.66690872485439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 120.8125, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 239.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 3998, "num_agent_steps_trained": 3998}, "sampler_results": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 14.89179104477612, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": -0.08582089552238806, "player_2": 0.08582089552238806}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [15, 12, 6, 20, 9, 14, 25, 24, 16, 19, 11, 18, 10, 13, 14, 20, 12, 13, 10, 19, 20, 18, 16, 15, 15, 11, 11, 15, 7, 14, 14, 16, 11, 22, 9, 13, 18, 19, 21, 8, 19, 18, 6, 17, 9, 6, 14, 14, 20, 23, 19, 24, 21, 18, 24, 11, 17, 15, 9, 7, 5, 19, 12, 12, 12, 9, 13, 22, 24, 9, 9, 17, 20, 14, 10, 25, 12, 13, 14, 14, 14, 15, 9, 6, 11, 21, 24, 17, 9, 16, 26, 33, 13, 17, 16, 14, 10, 17, 15, 16, 15, 11, 11, 13, 8, 7, 8, 25, 25, 7, 16, 11, 19, 20, 19, 13, 13, 21, 22, 14, 16, 17, 11, 18, 14, 21, 12, 13, 12, 25, 6, 10, 18, 16, 13, 17, 13, 11, 16, 22, 14, 34, 13, 15, 8, 22, 14, 14, 17, 24, 19, 14, 8, 15, 10, 24, 14, 22, 10, 15, 17, 16, 15, 14, 18, 25, 12, 9, 14, 10, 14, 8, 8, 15, 11, 15, 8, 10, 15, 10, 14, 12, 8, 13, 12, 18, 13, 12, 7, 7, 12, 16, 15, 11, 18, 14, 14, 17, 21, 14, 23, 9, 9, 14, 17, 22, 18, 9, 16, 18, 15, 16, 11, 9, 15, 8, 19, 8, 19, 17, 10, 22, 14, 11, 26, 17, 12, 8, 17, 13, 15, 19, 22, 10, 21, 7, 16, 9, 20, 12, 7, 24, 26, 15, 10, 20, 15, 15, 13, 8, 16, 16, 12, 9, 11, 25, 14, 7, 13, 13, 28, 14, 25, 13, 18, 15, 15, 16], "policy_player_1_reward": [-1.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, -2.0, 1.0, 1.0, -1.0, -1.0, 1.0, 2.0, 1.0, -2.0, 1.0, 1.0, -2.0, -2.0, -1.0, -2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -2.0, 2.0, 1.0, -2.0, 2.0, 1.0, 2.0, -2.0, -2.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, -2.0, -1.0, 1.0, 2.0, 1.0, -1.0, -1.0, 2.0, -1.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, -1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, -1.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, 2.0, 2.0, -1.0, 1.0, -2.0, -2.0, 1.0, 1.0, 1.0, 1.0, -2.0, -2.0, -1.0, -2.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, -2.0, -1.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, -1.0, 2.0, 1.0, 1.0, -2.0, -1.0, 2.0, -1.0, -1.0, 1.0, -2.0, -1.0, 2.0, -2.0, -1.0, 2.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, -2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, 1.0, -2.0, -1.0, -2.0, -1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, 1.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -1.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0], "policy_player_2_reward": [1.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, 2.0, -1.0, -1.0, 1.0, 1.0, -1.0, -2.0, -1.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, 2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -1.0, 2.0, -2.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -2.0, -1.0, 2.0, 1.0, -1.0, -2.0, -1.0, 1.0, 1.0, -2.0, 1.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, 1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, 1.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -2.0, 1.0, -1.0, 2.0, 2.0, -1.0, -1.0, -1.0, -1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, 2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, 1.0, -2.0, -1.0, -1.0, 2.0, 1.0, -2.0, 1.0, 1.0, -1.0, 2.0, 1.0, -2.0, 2.0, 1.0, -2.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, 2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -2.0, 2.0, 2.0, -2.0, 1.0, -1.0, 2.0, 1.0, 2.0, 1.0, -2.0, -2.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, -1.0, -2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -2.0, 2.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7394457978075577, "mean_inference_ms": 2.0670380171552076, "mean_action_processing_ms": 0.21004741595390314, "mean_env_wait_ms": 0.13707018211905533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.013259399194227126, "ViewRequirementAgentConnector_ms": 0.2529620592965811}}, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 14.89179104477612, "episodes_this_iter": 268, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": -0.08582089552238806, "player_2": 0.08582089552238806}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [15, 12, 6, 20, 9, 14, 25, 24, 16, 19, 11, 18, 10, 13, 14, 20, 12, 13, 10, 19, 20, 18, 16, 15, 15, 11, 11, 15, 7, 14, 14, 16, 11, 22, 9, 13, 18, 19, 21, 8, 19, 18, 6, 17, 9, 6, 14, 14, 20, 23, 19, 24, 21, 18, 24, 11, 17, 15, 9, 7, 5, 19, 12, 12, 12, 9, 13, 22, 24, 9, 9, 17, 20, 14, 10, 25, 12, 13, 14, 14, 14, 15, 9, 6, 11, 21, 24, 17, 9, 16, 26, 33, 13, 17, 16, 14, 10, 17, 15, 16, 15, 11, 11, 13, 8, 7, 8, 25, 25, 7, 16, 11, 19, 20, 19, 13, 13, 21, 22, 14, 16, 17, 11, 18, 14, 21, 12, 13, 12, 25, 6, 10, 18, 16, 13, 17, 13, 11, 16, 22, 14, 34, 13, 15, 8, 22, 14, 14, 17, 24, 19, 14, 8, 15, 10, 24, 14, 22, 10, 15, 17, 16, 15, 14, 18, 25, 12, 9, 14, 10, 14, 8, 8, 15, 11, 15, 8, 10, 15, 10, 14, 12, 8, 13, 12, 18, 13, 12, 7, 7, 12, 16, 15, 11, 18, 14, 14, 17, 21, 14, 23, 9, 9, 14, 17, 22, 18, 9, 16, 18, 15, 16, 11, 9, 15, 8, 19, 8, 19, 17, 10, 22, 14, 11, 26, 17, 12, 8, 17, 13, 15, 19, 22, 10, 21, 7, 16, 9, 20, 12, 7, 24, 26, 15, 10, 20, 15, 15, 13, 8, 16, 16, 12, 9, 11, 25, 14, 7, 13, 13, 28, 14, 25, 13, 18, 15, 15, 16], "policy_player_1_reward": [-1.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, -2.0, 1.0, 1.0, -1.0, -1.0, 1.0, 2.0, 1.0, -2.0, 1.0, 1.0, -2.0, -2.0, -1.0, -2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -2.0, 2.0, 1.0, -2.0, 2.0, 1.0, 2.0, -2.0, -2.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, -2.0, -1.0, 1.0, 2.0, 1.0, -1.0, -1.0, 2.0, -1.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, -1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, -1.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, 2.0, 2.0, -1.0, 1.0, -2.0, -2.0, 1.0, 1.0, 1.0, 1.0, -2.0, -2.0, -1.0, -2.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, -2.0, -1.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, -1.0, 2.0, 1.0, 1.0, -2.0, -1.0, 2.0, -1.0, -1.0, 1.0, -2.0, -1.0, 2.0, -2.0, -1.0, 2.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, -2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, 1.0, -2.0, -1.0, -2.0, -1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, 1.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -1.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0], "policy_player_2_reward": [1.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, 2.0, -1.0, -1.0, 1.0, 1.0, -1.0, -2.0, -1.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, 2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -1.0, 2.0, -2.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -2.0, -1.0, 2.0, 1.0, -1.0, -2.0, -1.0, 1.0, 1.0, -2.0, 1.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, 1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, 1.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -2.0, 1.0, -1.0, 2.0, 2.0, -1.0, -1.0, -1.0, -1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, 2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, 1.0, -2.0, -1.0, -1.0, 2.0, 1.0, -2.0, 1.0, 1.0, -1.0, 2.0, 1.0, -2.0, 2.0, 1.0, -2.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, 2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -2.0, 2.0, 2.0, -2.0, 1.0, -1.0, 2.0, 1.0, 2.0, 1.0, -2.0, -2.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, -1.0, -2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -2.0, 2.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7394457978075577, "mean_inference_ms": 2.0670380171552076, "mean_action_processing_ms": 0.21004741595390314, "mean_env_wait_ms": 0.13707018211905533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.013259399194227126, "ViewRequirementAgentConnector_ms": 0.2529620592965811}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3998, "num_agent_steps_trained": 3998, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.81718499738915, "num_env_steps_trained_throughput_per_sec": 166.81718499738915, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3998, "timers": {"training_iteration_time_ms": 23978.345, "sample_time_ms": 6424.213, "learn_time_ms": 17544.507, "learn_throughput": 227.992, "synch_weights_time_ms": 9.625}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 3998, "num_agent_steps_trained": 3998}, "done": false, "episodes_total": 268, "training_iteration": 1, "trial_id": "d977f_00000", "date": "2024-03-27_14-48-11", "timestamp": 1711550891, "time_this_iter_s": 28.72934103012085, "time_total_s": 28.72934103012085, "pid": 8992, "hostname": "DESKTOP-RNN7NJG", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "Coup", "env_config": {"action_space": "Discrete(11)", "observation_space": "MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11])"}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": true, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "am_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x00000217B5673A30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 1, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"multiagent": {"policy_mapping_fn": "<function policy_mapping_fn at 0x00000217B56711B0>"}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 2, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": true, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"player_1": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "player_2": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "random": ["<class '__main__.RandomPolicyActionMask'>", "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function custom_eval_function at 0x00000217B5673B50>", "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 28.72934103012085, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 14.73658536585366, "ram_util_percent": 95.78536585365855}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 13.045, "episode_media": {}, "episodes_this_iter": 200, "policy_reward_min": {"random": -2.0, "player_2": -2.0, "player_1": -2.0}, "policy_reward_max": {"random": 2.0, "player_2": 2.0, "player_1": 2.0}, "policy_reward_mean": {"random": -0.21243523316062177, "player_2": 0.2980769230769231, "player_1": 0.0970873786407767}, "custom_metrics": {}, "hist_stats": {"episode_lengths": [13, 26, 18, 14, 19, 10, 18, 18, 16, 9, 10, 18, 8, 12, 21, 11, 10, 13, 18, 14, 7, 12, 8, 12, 7, 26, 18, 14, 12, 10, 14, 12, 5, 14, 5, 14, 13, 16, 18, 14, 14, 9, 11, 12, 17, 11, 7, 11, 16, 7, 12, 15, 18, 11, 12, 7, 7, 11, 10, 11, 15, 8, 11, 12, 8, 17, 11, 13, 15, 13, 10, 14, 11, 12, 23, 16, 13, 14, 16, 13, 17, 6, 14, 9, 15, 10, 9, 26, 17, 9, 12, 15, 8, 11, 14, 9, 8, 19, 14, 7, 14, 17, 13, 23, 9, 9, 18, 18, 7, 17, 12, 9, 12, 17, 22, 14, 6, 21, 9, 19, 16, 14, 18, 14, 16, 15, 12, 14, 13, 13, 15, 16, 12, 9, 13, 11, 13, 13, 16, 8, 19, 9, 13, 19, 8, 7, 12, 18, 15, 11, 20, 14, 17, 12, 8, 6, 17, 12, 9, 6, 7, 9, 10, 9, 14, 17, 15, 18, 6, 11, 9, 15, 13, 7, 16, 11, 15, 12, 11, 14, 13, 10, 9, 13, 11, 14, 30, 17, 6, 10, 14, 13, 10, 17, 10, 14, 18, 6, 19, 17], "policy_random_reward": [-2.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 2.0, 1.0, -2.0, 2.0, 1.0, -1.0, -1.0, -2.0, -1.0, -2.0, -2.0, 2.0, 1.0, -1.0, -1.0, 1.0, -2.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -2.0, 1.0, -2.0, 2.0, -2.0, 2.0, -2.0, 2.0, -1.0, -2.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -2.0, 2.0, -2.0, 2.0, -2.0, 2.0, -2.0, 2.0, 1.0, -1.0, 2.0, -2.0, 2.0, -2.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 2.0, -2.0, 1.0, -2.0, 2.0, -1.0, 1.0, 1.0, -1.0, -2.0, 2.0, -2.0, 2.0, -2.0, -2.0, 2.0, -2.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, 1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 2.0, -2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -1.0, -1.0, -2.0, 2.0, -2.0, 2.0, 1.0, -1.0, -2.0, 2.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, 2.0, -2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -2.0, -1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 2.0, -2.0, 2.0, -2.0, 2.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, 2.0, -1.0, -2.0, -1.0, 2.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -2.0, -1.0, 1.0, -1.0, 1.0, 2.0, -1.0, 1.0, -1.0, -2.0, -1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 1.0, 1.0, -1.0], "policy_player_2_reward": [2.0, 1.0, 1.0, -2.0, 2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -1.0, -1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, -2.0, -2.0, 1.0, 2.0, 1.0, -1.0, 2.0, -1.0, -2.0, 1.0, 1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -2.0, 2.0, 1.0, 2.0, 1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, 2.0, -2.0, -1.0, 1.0, 2.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 1.0, -2.0, -1.0, 1.0, -2.0, 2.0, 2.0, 1.0, 2.0, -2.0, 1.0, 1.0, -1.0, -2.0, 1.0, 1.0, -2.0, 2.0, -2.0, 2.0, -2.0, -1.0, 1.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, -1.0, -2.0, 2.0, 1.0], "policy_player_1_reward": [2.0, -2.0, -2.0, -2.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 1.0, -2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 2.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -1.0, -1.0, 2.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -1.0, -1.0, 1.0, 2.0, 1.0, -2.0, 1.0, 2.0, -1.0, 2.0, -1.0, 2.0, 2.0, -1.0, -2.0, 2.0, 1.0, -1.0, 2.0, -1.0, 1.0, 2.0, -1.0, 1.0, -2.0, 1.0, 2.0, -2.0, -1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, -2.0, 1.0, -1.0, -2.0, 1.0, 2.0, 1.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8410878935044012, "mean_inference_ms": 1.2592621189091282, "mean_action_processing_ms": 0.18569405998803923, "mean_env_wait_ms": 0.1192598732230974, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.02359353368808342, "ViewRequirementAgentConnector_ms": 0.3173122433331771}, "player_1_winrate": 0.5242718446601942, "player_2_winrate": 0.6057692307692307, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {}, "episode_media": {}, "info": {"learner": {"player_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.583438838696947, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8650772344832327, "policy_loss": -0.03657729763848086, "vf_loss": 1.8983631973173105, "vf_explained_var": 0.11351362022699095, "kl": 0.016456694300735583, "entropy": 1.568879471573175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 121.94117647058823, "num_grad_updates_lifetime": 765.5, "diff_num_grad_updates_vs_sampler_policy": 254.5}, "player_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8689231254160403, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7980328233291705, "policy_loss": -0.03322693360387348, "vf_loss": 1.828487092256546, "vf_explained_var": 0.14928857013583183, "kl": 0.013863313673708426, "entropy": 1.6159443656603496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 120.4375, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 239.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 7998, "num_agent_steps_trained": 7998}, "sampler_results": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 12.773162939297125, "episode_media": {}, "episodes_this_iter": 313, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.07987220447284345, "player_2": -0.07987220447284345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [8, 12, 14, 11, 16, 17, 13, 7, 18, 18, 11, 9, 12, 17, 18, 11, 10, 11, 11, 13, 7, 15, 9, 13, 16, 5, 14, 6, 11, 16, 16, 14, 9, 14, 8, 17, 12, 15, 12, 9, 16, 12, 17, 15, 13, 10, 13, 17, 16, 16, 12, 14, 8, 21, 13, 9, 11, 6, 19, 8, 10, 13, 10, 12, 6, 24, 18, 10, 14, 12, 15, 8, 13, 13, 6, 6, 16, 9, 11, 23, 9, 8, 18, 14, 23, 8, 9, 9, 18, 12, 13, 13, 16, 7, 12, 6, 8, 9, 9, 18, 12, 13, 16, 15, 24, 17, 10, 13, 10, 12, 19, 13, 12, 18, 11, 17, 10, 11, 6, 7, 11, 14, 21, 25, 19, 15, 10, 16, 9, 10, 14, 22, 19, 10, 10, 6, 7, 10, 12, 15, 11, 14, 13, 19, 16, 5, 9, 18, 18, 19, 16, 8, 12, 8, 12, 12, 20, 18, 16, 8, 6, 13, 13, 16, 21, 16, 11, 20, 11, 8, 12, 21, 10, 22, 12, 8, 23, 5, 11, 19, 18, 12, 8, 14, 15, 9, 11, 17, 9, 17, 16, 14, 14, 10, 13, 6, 17, 12, 15, 12, 14, 9, 7, 15, 7, 19, 14, 11, 14, 6, 10, 6, 10, 17, 15, 6, 15, 14, 6, 14, 10, 10, 15, 14, 12, 18, 12, 9, 10, 11, 12, 11, 14, 11, 11, 11, 11, 15, 13, 7, 11, 10, 18, 13, 22, 14, 10, 16, 11, 11, 8, 6, 12, 13, 8, 6, 12, 15, 8, 20, 14, 16, 8, 19, 14, 20, 13, 10, 5, 10, 7, 12, 9, 16, 14, 9, 13, 15, 18, 6, 15, 10, 11, 15, 10, 13, 15, 15, 9, 19, 18, 14, 4, 20, 15, 15, 19, 15, 9, 15, 13, 12, 11, 14, 11, 10, 8, 11, 17, 16, 15, 13, 14], "policy_player_1_reward": [2.0, 2.0, -2.0, 1.0, -1.0, -2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 2.0, -1.0, 2.0, 2.0, -1.0, -2.0, -1.0, -2.0, 2.0, -2.0, 2.0, 2.0, 2.0, 1.0, -1.0, 1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, -2.0, -2.0, -1.0, 2.0, -2.0, -1.0, -1.0, -2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, 1.0, 1.0, -2.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 2.0, 1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 2.0, 2.0, -1.0, -2.0, 2.0, -2.0, -2.0, 1.0, -2.0, -1.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, 2.0, -2.0, -1.0, -1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, 2.0, -1.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 1.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -2.0, -2.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, 1.0, 1.0, -2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -1.0, -1.0, 2.0, -2.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, -2.0, 2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, -2.0, 2.0, -2.0, -1.0, 2.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 1.0, -1.0, -1.0, 2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, -1.0, 2.0, 1.0, -1.0, -2.0, 2.0, -1.0, 1.0, 2.0, 1.0, 2.0, 2.0, -1.0, 1.0, -2.0, -2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 1.0], "policy_player_2_reward": [-2.0, -2.0, 2.0, -1.0, 1.0, 2.0, -1.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -2.0, 1.0, -2.0, -2.0, 1.0, 2.0, 1.0, 2.0, -2.0, 2.0, -2.0, -2.0, -2.0, -1.0, 1.0, -1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -1.0, -2.0, -1.0, -2.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, 2.0, 2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, -1.0, -1.0, 2.0, 2.0, 2.0, 1.0, -1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -2.0, -1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -2.0, -2.0, 1.0, 2.0, -2.0, 2.0, 2.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, -2.0, 2.0, 1.0, 1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, -2.0, 1.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -1.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, -1.0, -1.0, 2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 1.0, 1.0, -2.0, 2.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, 2.0, -2.0, -1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, 2.0, -2.0, 2.0, 1.0, -2.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -1.0, 1.0, 1.0, -2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -1.0, -1.0, 1.0, -2.0, -1.0, 1.0, 2.0, -2.0, 1.0, -1.0, -2.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, 2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7004124157663176, "mean_inference_ms": 1.9812200945935556, "mean_action_processing_ms": 0.18984044611381617, "mean_env_wait_ms": 0.12584769973001822, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.016347554545052136, "ViewRequirementAgentConnector_ms": 0.2089989832795847}}, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 12.773162939297125, "episodes_this_iter": 313, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.07987220447284345, "player_2": -0.07987220447284345}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [8, 12, 14, 11, 16, 17, 13, 7, 18, 18, 11, 9, 12, 17, 18, 11, 10, 11, 11, 13, 7, 15, 9, 13, 16, 5, 14, 6, 11, 16, 16, 14, 9, 14, 8, 17, 12, 15, 12, 9, 16, 12, 17, 15, 13, 10, 13, 17, 16, 16, 12, 14, 8, 21, 13, 9, 11, 6, 19, 8, 10, 13, 10, 12, 6, 24, 18, 10, 14, 12, 15, 8, 13, 13, 6, 6, 16, 9, 11, 23, 9, 8, 18, 14, 23, 8, 9, 9, 18, 12, 13, 13, 16, 7, 12, 6, 8, 9, 9, 18, 12, 13, 16, 15, 24, 17, 10, 13, 10, 12, 19, 13, 12, 18, 11, 17, 10, 11, 6, 7, 11, 14, 21, 25, 19, 15, 10, 16, 9, 10, 14, 22, 19, 10, 10, 6, 7, 10, 12, 15, 11, 14, 13, 19, 16, 5, 9, 18, 18, 19, 16, 8, 12, 8, 12, 12, 20, 18, 16, 8, 6, 13, 13, 16, 21, 16, 11, 20, 11, 8, 12, 21, 10, 22, 12, 8, 23, 5, 11, 19, 18, 12, 8, 14, 15, 9, 11, 17, 9, 17, 16, 14, 14, 10, 13, 6, 17, 12, 15, 12, 14, 9, 7, 15, 7, 19, 14, 11, 14, 6, 10, 6, 10, 17, 15, 6, 15, 14, 6, 14, 10, 10, 15, 14, 12, 18, 12, 9, 10, 11, 12, 11, 14, 11, 11, 11, 11, 15, 13, 7, 11, 10, 18, 13, 22, 14, 10, 16, 11, 11, 8, 6, 12, 13, 8, 6, 12, 15, 8, 20, 14, 16, 8, 19, 14, 20, 13, 10, 5, 10, 7, 12, 9, 16, 14, 9, 13, 15, 18, 6, 15, 10, 11, 15, 10, 13, 15, 15, 9, 19, 18, 14, 4, 20, 15, 15, 19, 15, 9, 15, 13, 12, 11, 14, 11, 10, 8, 11, 17, 16, 15, 13, 14], "policy_player_1_reward": [2.0, 2.0, -2.0, 1.0, -1.0, -2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 2.0, -1.0, 2.0, 2.0, -1.0, -2.0, -1.0, -2.0, 2.0, -2.0, 2.0, 2.0, 2.0, 1.0, -1.0, 1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, -2.0, -2.0, -1.0, 2.0, -2.0, -1.0, -1.0, -2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, 1.0, 1.0, -2.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 2.0, 1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 2.0, 2.0, -1.0, -2.0, 2.0, -2.0, -2.0, 1.0, -2.0, -1.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, 2.0, -2.0, -1.0, -1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, 2.0, -1.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 1.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -2.0, -2.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, 1.0, 1.0, -2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -1.0, -1.0, 2.0, -2.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, -2.0, 2.0, 1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, -2.0, 2.0, -2.0, -1.0, 2.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 1.0, -1.0, -1.0, 2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, -1.0, 2.0, 1.0, -1.0, -2.0, 2.0, -1.0, 1.0, 2.0, 1.0, 2.0, 2.0, -1.0, 1.0, -2.0, -2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 1.0], "policy_player_2_reward": [-2.0, -2.0, 2.0, -1.0, 1.0, 2.0, -1.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -2.0, 1.0, -2.0, -2.0, 1.0, 2.0, 1.0, 2.0, -2.0, 2.0, -2.0, -2.0, -2.0, -1.0, 1.0, -1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -1.0, -2.0, -1.0, -2.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, 2.0, 2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 2.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, -1.0, -1.0, 2.0, 2.0, 2.0, 1.0, -1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -2.0, -1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -2.0, -2.0, 1.0, 2.0, -2.0, 2.0, 2.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, -2.0, 2.0, 1.0, 1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, -2.0, 1.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -1.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, -1.0, -1.0, 2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 1.0, 1.0, -2.0, 2.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, 2.0, -2.0, -1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, 2.0, -2.0, 2.0, 1.0, -2.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -1.0, 1.0, 1.0, -2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -1.0, -1.0, 1.0, -2.0, -1.0, 1.0, 2.0, -2.0, 1.0, -1.0, -2.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, 2.0, 1.0, -1.0, 2.0, 2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7004124157663176, "mean_inference_ms": 1.9812200945935556, "mean_action_processing_ms": 0.18984044611381617, "mean_env_wait_ms": 0.12584769973001822, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.016347554545052136, "ViewRequirementAgentConnector_ms": 0.2089989832795847}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 7998, "num_agent_steps_trained": 7998, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.21106013246217, "num_env_steps_trained_throughput_per_sec": 190.21106013246217, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 7998, "timers": {"training_iteration_time_ms": 22503.808, "sample_time_ms": 6086.666, "learn_time_ms": 16409.108, "learn_throughput": 243.767, "synch_weights_time_ms": 7.483}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 7998, "num_agent_steps_trained": 7998}, "done": false, "episodes_total": 581, "training_iteration": 2, "trial_id": "d977f_00000", "date": "2024-03-27_14-48-37", "timestamp": 1711550917, "time_this_iter_s": 25.512413263320923, "time_total_s": 54.24175429344177, "pid": 8992, "hostname": "DESKTOP-RNN7NJG", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "Coup", "env_config": {"action_space": "Discrete(11)", "observation_space": "MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11])"}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": true, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "am_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x00000217B5750700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 1, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"multiagent": {"policy_mapping_fn": "<function policy_mapping_fn at 0x00000217B5750790>"}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 2, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": true, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"player_1": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "player_2": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "random": ["<class '__main__.RandomPolicyActionMask'>", "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function custom_eval_function at 0x00000217B5673AC0>", "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 54.24175429344177, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 11.862857142857141, "ram_util_percent": 94.76285714285716}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 12.425, "episode_media": {}, "episodes_this_iter": 200, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0, "random": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0, "random": 2.0}, "policy_reward_mean": {"player_1": 0.4725274725274725, "player_2": 0.12871287128712872, "random": -0.2692307692307692}, "custom_metrics": {}, "hist_stats": {"episode_lengths": [7, 18, 16, 12, 12, 10, 10, 14, 10, 11, 14, 9, 13, 7, 6, 22, 10, 9, 13, 11, 11, 10, 13, 16, 12, 9, 16, 19, 13, 15, 8, 15, 18, 13, 7, 18, 13, 15, 18, 9, 10, 10, 6, 17, 13, 15, 23, 14, 7, 23, 13, 12, 15, 8, 5, 18, 12, 13, 8, 8, 6, 5, 20, 17, 6, 10, 11, 11, 21, 17, 17, 9, 11, 9, 14, 13, 25, 6, 5, 7, 10, 7, 6, 15, 7, 10, 11, 15, 9, 16, 15, 8, 12, 21, 14, 16, 10, 7, 13, 10, 10, 13, 10, 13, 13, 10, 10, 10, 18, 19, 15, 5, 24, 13, 5, 14, 12, 7, 18, 6, 9, 13, 27, 11, 17, 8, 12, 16, 18, 13, 17, 16, 13, 8, 13, 12, 17, 7, 22, 12, 6, 7, 13, 9, 7, 15, 9, 6, 11, 12, 14, 12, 11, 8, 6, 10, 12, 15, 8, 13, 8, 18, 18, 21, 10, 8, 12, 8, 15, 16, 25, 14, 12, 15, 10, 10, 14, 19, 6, 8, 23, 12, 16, 12, 12, 6, 10, 9, 10, 15, 21, 19, 13, 6, 9, 21, 8, 19, 7, 16], "policy_player_1_reward": [2.0, -1.0, -2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -1.0, 1.0, -2.0, -1.0, -2.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, -1.0, -2.0, -2.0, 2.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, 2.0, -1.0, 2.0, -2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, -2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 1.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 1.0, 1.0], "policy_player_2_reward": [-2.0, -1.0, 1.0, 1.0, 2.0, -1.0, -2.0, 2.0, 2.0, 1.0, -2.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 2.0, 2.0, -2.0, -1.0, 2.0, -2.0, 1.0, -1.0, -1.0, 1.0, -2.0, -1.0, 2.0, 2.0, 2.0, 2.0, -1.0, -2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 2.0, -2.0, 2.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 1.0, 2.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, 2.0, 2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -2.0, 1.0, -1.0, -2.0, 2.0, 1.0, -2.0, 2.0, -1.0, -1.0, -2.0, 2.0, 2.0, 1.0, -1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, 2.0, 2.0, -2.0, -2.0, 1.0, -1.0, -2.0, -1.0, -2.0, -1.0, 2.0, -1.0], "policy_random_reward": [1.0, -1.0, -1.0, 1.0, 1.0, 2.0, -2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, -1.0, 2.0, -1.0, -2.0, 1.0, -1.0, 2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0, 1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 1.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, 1.0, -2.0, 1.0, -1.0, -1.0, 1.0, -1.0, 2.0, -2.0, -2.0, 2.0, -2.0, -2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -2.0, 2.0, -2.0, 1.0, 2.0, -1.0, -1.0, -2.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, -1.0, -2.0, 2.0, 1.0, 2.0, -2.0, -2.0, 2.0, -2.0, 2.0, 1.0, -2.0, -1.0, -1.0, 1.0, 2.0, -2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, -1.0, -2.0, 2.0, -2.0, -1.0, 1.0, -1.0, -2.0, 2.0, -1.0, 1.0, 1.0, -1.0, -2.0, -1.0, 1.0, -2.0, -1.0, -2.0, 1.0, -1.0, -1.0, 1.0, -1.0, -2.0, -1.0, -1.0, -1.0, -2.0, -1.0, 2.0, -1.0, 2.0, -2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -2.0, 1.0, -1.0, 2.0, -2.0, -1.0, 2.0, -2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, 2.0, -2.0, 1.0, -1.0, 1.0, -1.0, -2.0, -1.0, -1.0, -1.0, 1.0, 2.0, -2.0, -2.0, -2.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, 1.0, -2.0, 2.0, -2.0, -2.0, -2.0, 1.0, -2.0, 2.0, -1.0, 1.0, -2.0, 2.0, 1.0, -2.0, 1.0, 2.0, -1.0, 2.0, -2.0, 1.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, -1.0, 2.0, 1.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8383776249479985, "mean_inference_ms": 1.211140756848198, "mean_action_processing_ms": 0.18309499746427868, "mean_env_wait_ms": 0.11515671945637262, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.022359597200603154, "ViewRequirementAgentConnector_ms": 0.32149498173267166}, "player_1_winrate": 0.6483516483516484, "player_2_winrate": 0.5346534653465347, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {}, "episode_media": {}, "info": {"learner": {"player_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7082119663556417, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8095055157063054, "policy_loss": -0.03644432449535302, "vf_loss": 1.8429730805696225, "vf_explained_var": 0.1395599692475562, "kl": 0.01488380019639296, "entropy": 1.4980913470773136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 122.47058823529412, "num_grad_updates_lifetime": 1275.5, "diff_num_grad_updates_vs_sampler_policy": 254.5}, "player_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.42810084660848, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7394497847557069, "policy_loss": -0.03509574044806262, "vf_loss": 1.7711226473914252, "vf_explained_var": 0.16832770705223082, "kl": 0.01711440489040999, "entropy": 1.5547107805146112, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.86666666666666, "num_grad_updates_lifetime": 1185.5, "diff_num_grad_updates_vs_sampler_policy": 224.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 11998, "num_agent_steps_trained": 11998}, "sampler_results": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 11.723529411764705, "episode_media": {}, "episodes_this_iter": 340, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.047058823529411764, "player_2": -0.047058823529411764}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [11, 13, 14, 13, 7, 17, 10, 10, 14, 10, 10, 18, 9, 12, 17, 11, 8, 11, 8, 8, 10, 11, 12, 17, 14, 10, 9, 14, 11, 11, 14, 21, 13, 18, 21, 17, 9, 14, 14, 17, 8, 19, 15, 6, 15, 12, 12, 9, 7, 11, 14, 10, 8, 10, 15, 12, 14, 10, 19, 9, 15, 8, 13, 9, 11, 14, 12, 10, 5, 21, 6, 7, 7, 13, 7, 11, 13, 11, 8, 7, 6, 6, 15, 11, 13, 5, 16, 13, 13, 13, 17, 12, 14, 7, 8, 14, 12, 15, 9, 12, 9, 10, 11, 21, 9, 14, 13, 11, 12, 10, 7, 13, 8, 6, 14, 17, 12, 15, 10, 7, 7, 7, 6, 10, 6, 18, 12, 6, 13, 14, 16, 8, 5, 10, 12, 14, 10, 8, 12, 5, 7, 6, 10, 5, 12, 13, 8, 6, 12, 13, 25, 12, 6, 13, 10, 13, 10, 9, 8, 9, 10, 6, 16, 17, 15, 12, 9, 21, 7, 19, 12, 12, 11, 6, 13, 7, 12, 10, 6, 13, 14, 11, 9, 8, 13, 12, 9, 10, 8, 15, 11, 9, 7, 13, 23, 14, 8, 16, 7, 12, 17, 6, 19, 5, 16, 11, 13, 9, 9, 23, 20, 11, 16, 12, 13, 11, 9, 14, 14, 19, 11, 9, 17, 10, 12, 9, 14, 15, 9, 16, 11, 7, 10, 8, 8, 6, 8, 10, 16, 11, 8, 15, 10, 14, 10, 15, 7, 16, 12, 14, 15, 8, 8, 12, 6, 9, 8, 12, 16, 18, 11, 18, 18, 8, 13, 13, 14, 7, 15, 11, 15, 12, 11, 8, 7, 20, 14, 14, 15, 9, 11, 10, 8, 15, 16, 12, 14, 9, 8, 13, 18, 10, 26, 13, 7, 10, 22, 11, 16, 9, 15, 13, 10, 13, 16, 18, 11, 9, 13, 12, 10, 9, 8, 12, 10, 19, 19, 11, 10, 12, 9, 11, 13, 16, 8, 11, 13, 13, 10, 8, 10, 5, 14, 14, 16, 12, 9, 12, 8, 16], "policy_player_1_reward": [2.0, 1.0, 2.0, 2.0, -1.0, 2.0, -1.0, -1.0, -1.0, -2.0, 2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -2.0, 1.0, -1.0, 2.0, -1.0, -1.0, 1.0, 1.0, -2.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, 2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 1.0, -2.0, 1.0, -2.0, 1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -2.0, 1.0, -2.0, -1.0, -2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 2.0, -1.0, -2.0, 1.0, -2.0, 2.0, -2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -2.0, -1.0, 1.0, -2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, 1.0, -1.0, -2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, 1.0, -2.0, 2.0, -2.0, -2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -1.0, -1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 2.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -2.0, -2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 2.0, -1.0, -2.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, -1.0, 2.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 2.0, -1.0, -1.0, -1.0, 1.0, -2.0, 1.0, 2.0, -1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -1.0, -2.0, -1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -2.0, 2.0, -2.0, 2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -2.0, -2.0, -1.0, 1.0, -1.0, -1.0, 2.0, -2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, -2.0, -2.0, -1.0, 2.0, -2.0, -1.0, 1.0, 1.0, 1.0, -2.0, -1.0, 1.0, 2.0, 2.0, 2.0, -2.0, -2.0, 2.0, -1.0, 1.0, -1.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, 1.0], "policy_player_2_reward": [-2.0, -1.0, -2.0, -2.0, 1.0, -2.0, 1.0, 1.0, 1.0, 2.0, -2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -1.0, 1.0, -2.0, 1.0, 1.0, -1.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, -2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -1.0, 2.0, -1.0, 2.0, -1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 2.0, -1.0, 2.0, 1.0, 2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -2.0, 1.0, 2.0, -1.0, 2.0, -2.0, 2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 2.0, 1.0, -1.0, 2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, -1.0, 1.0, 2.0, -2.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, -1.0, 2.0, -2.0, 2.0, 2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -1.0, 1.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 1.0, 1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, 2.0, -2.0, -2.0, -2.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -2.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 2.0, 2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, 2.0, -1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -2.0, 1.0, 2.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, 1.0, -2.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -2.0, 1.0, 1.0, 1.0, -1.0, 2.0, -1.0, -2.0, 1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, 2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 2.0, -2.0, 2.0, -2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, -1.0, 1.0, 1.0, -2.0, 2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, -2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, -2.0, -2.0, 2.0, 2.0, 1.0, -2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 2.0, 1.0, -1.0, -2.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, -1.0, 1.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7043410213644, "mean_inference_ms": 1.921662463577402, "mean_action_processing_ms": 0.18476753138950852, "mean_env_wait_ms": 0.1217252621538097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.018079280853271484, "ViewRequirementAgentConnector_ms": 0.23339948233436136}}, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 11.723529411764705, "episodes_this_iter": 340, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.047058823529411764, "player_2": -0.047058823529411764}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [11, 13, 14, 13, 7, 17, 10, 10, 14, 10, 10, 18, 9, 12, 17, 11, 8, 11, 8, 8, 10, 11, 12, 17, 14, 10, 9, 14, 11, 11, 14, 21, 13, 18, 21, 17, 9, 14, 14, 17, 8, 19, 15, 6, 15, 12, 12, 9, 7, 11, 14, 10, 8, 10, 15, 12, 14, 10, 19, 9, 15, 8, 13, 9, 11, 14, 12, 10, 5, 21, 6, 7, 7, 13, 7, 11, 13, 11, 8, 7, 6, 6, 15, 11, 13, 5, 16, 13, 13, 13, 17, 12, 14, 7, 8, 14, 12, 15, 9, 12, 9, 10, 11, 21, 9, 14, 13, 11, 12, 10, 7, 13, 8, 6, 14, 17, 12, 15, 10, 7, 7, 7, 6, 10, 6, 18, 12, 6, 13, 14, 16, 8, 5, 10, 12, 14, 10, 8, 12, 5, 7, 6, 10, 5, 12, 13, 8, 6, 12, 13, 25, 12, 6, 13, 10, 13, 10, 9, 8, 9, 10, 6, 16, 17, 15, 12, 9, 21, 7, 19, 12, 12, 11, 6, 13, 7, 12, 10, 6, 13, 14, 11, 9, 8, 13, 12, 9, 10, 8, 15, 11, 9, 7, 13, 23, 14, 8, 16, 7, 12, 17, 6, 19, 5, 16, 11, 13, 9, 9, 23, 20, 11, 16, 12, 13, 11, 9, 14, 14, 19, 11, 9, 17, 10, 12, 9, 14, 15, 9, 16, 11, 7, 10, 8, 8, 6, 8, 10, 16, 11, 8, 15, 10, 14, 10, 15, 7, 16, 12, 14, 15, 8, 8, 12, 6, 9, 8, 12, 16, 18, 11, 18, 18, 8, 13, 13, 14, 7, 15, 11, 15, 12, 11, 8, 7, 20, 14, 14, 15, 9, 11, 10, 8, 15, 16, 12, 14, 9, 8, 13, 18, 10, 26, 13, 7, 10, 22, 11, 16, 9, 15, 13, 10, 13, 16, 18, 11, 9, 13, 12, 10, 9, 8, 12, 10, 19, 19, 11, 10, 12, 9, 11, 13, 16, 8, 11, 13, 13, 10, 8, 10, 5, 14, 14, 16, 12, 9, 12, 8, 16], "policy_player_1_reward": [2.0, 1.0, 2.0, 2.0, -1.0, 2.0, -1.0, -1.0, -1.0, -2.0, 2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -2.0, 1.0, -1.0, 2.0, -1.0, -1.0, 1.0, 1.0, -2.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, 2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 1.0, -2.0, 1.0, -2.0, 1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -2.0, 1.0, -2.0, -1.0, -2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 2.0, -1.0, -2.0, 1.0, -2.0, 2.0, -2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -2.0, -1.0, 1.0, -2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, 1.0, -1.0, -2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, -1.0, -2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, 1.0, -2.0, 2.0, -2.0, -2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -1.0, -1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, -2.0, 2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 2.0, 2.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 2.0, -2.0, -2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 2.0, -2.0, -2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 2.0, -1.0, -2.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, -1.0, 2.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 2.0, -1.0, -1.0, -1.0, 1.0, -2.0, 1.0, 2.0, -1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -1.0, 2.0, 2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -1.0, -2.0, -1.0, -1.0, -2.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -2.0, 2.0, -2.0, 2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -2.0, -2.0, -1.0, 1.0, -1.0, -1.0, 2.0, -2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, -1.0, 2.0, 2.0, -2.0, -2.0, -1.0, 2.0, -2.0, -1.0, 1.0, 1.0, 1.0, -2.0, -1.0, 1.0, 2.0, 2.0, 2.0, -2.0, -2.0, 2.0, -1.0, 1.0, -1.0, -2.0, -1.0, 2.0, 2.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, 1.0], "policy_player_2_reward": [-2.0, -1.0, -2.0, -2.0, 1.0, -2.0, 1.0, 1.0, 1.0, 2.0, -2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -1.0, 1.0, -2.0, 1.0, 1.0, -1.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, -2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 2.0, 2.0, 1.0, -1.0, 2.0, -1.0, 2.0, -1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 2.0, -1.0, 2.0, 1.0, 2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -2.0, 1.0, 2.0, -1.0, 2.0, -2.0, 2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 2.0, 1.0, -1.0, 2.0, -1.0, -1.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, -1.0, 1.0, 2.0, -2.0, -1.0, -2.0, -2.0, -1.0, -1.0, -2.0, 1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, -1.0, 2.0, -2.0, 2.0, 2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -1.0, 1.0, 1.0, 2.0, -2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 1.0, 1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, 2.0, -2.0, -2.0, -2.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -2.0, -2.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -2.0, 2.0, 2.0, 1.0, -1.0, -2.0, -2.0, -1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, 2.0, -1.0, -2.0, 2.0, 2.0, -1.0, 2.0, -2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -2.0, 1.0, 2.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, 1.0, -2.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -2.0, 1.0, 1.0, 1.0, -1.0, 2.0, -1.0, -2.0, 1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, 2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 2.0, -2.0, 2.0, -2.0, 1.0, 1.0, -2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, -1.0, 1.0, 1.0, -2.0, 2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, -2.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, 1.0, -2.0, -2.0, 2.0, 2.0, 1.0, -2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 2.0, 1.0, -1.0, -2.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, -1.0, 1.0, 2.0, 1.0, -2.0, -2.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7043410213644, "mean_inference_ms": 1.921662463577402, "mean_action_processing_ms": 0.18476753138950852, "mean_env_wait_ms": 0.1217252621538097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.018079280853271484, "ViewRequirementAgentConnector_ms": 0.23339948233436136}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 11998, "num_agent_steps_trained": 11998, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 183.72927539210588, "num_env_steps_trained_throughput_per_sec": 183.72927539210588, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 11998, "timers": {"training_iteration_time_ms": 22259.593, "sample_time_ms": 5950.993, "learn_time_ms": 16300.949, "learn_throughput": 245.384, "synch_weights_time_ms": 6.947}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 11998, "num_agent_steps_trained": 11998}, "done": false, "episodes_total": 921, "training_iteration": 3, "trial_id": "d977f_00000", "date": "2024-03-27_14-49-03", "timestamp": 1711550943, "time_this_iter_s": 25.74727725982666, "time_total_s": 79.98903155326843, "pid": 8992, "hostname": "DESKTOP-RNN7NJG", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "Coup", "env_config": {"action_space": "Discrete(11)", "observation_space": "MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11])"}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": true, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "am_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x00000217B5750940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 1, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"multiagent": {"policy_mapping_fn": "<function policy_mapping_fn at 0x00000217B57508B0>"}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 2, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": true, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"player_1": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "player_2": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "random": ["<class '__main__.RandomPolicyActionMask'>", "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function custom_eval_function at 0x00000217B5750550>", "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 79.98903155326843, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 10.93611111111111, "ram_util_percent": 94.35277777777777}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 11.63, "episode_media": {}, "episodes_this_iter": 200, "policy_reward_min": {"random": -2.0, "player_2": -2.0, "player_1": -2.0}, "policy_reward_max": {"random": 2.0, "player_2": 2.0, "player_1": 2.0}, "policy_reward_mean": {"random": -0.22631578947368422, "player_2": 0.19811320754716982, "player_1": 0.21153846153846154}, "custom_metrics": {}, "hist_stats": {"episode_lengths": [7, 18, 11, 13, 9, 9, 12, 23, 17, 18, 18, 19, 6, 17, 13, 13, 16, 7, 13, 14, 9, 6, 15, 11, 17, 14, 11, 11, 13, 17, 5, 10, 11, 7, 7, 11, 10, 8, 6, 5, 21, 12, 6, 8, 7, 21, 12, 15, 22, 10, 16, 10, 4, 25, 7, 6, 7, 6, 12, 8, 8, 5, 10, 6, 11, 10, 10, 27, 21, 8, 13, 8, 12, 9, 5, 14, 14, 6, 8, 13, 6, 19, 12, 10, 17, 10, 8, 10, 11, 17, 21, 16, 7, 9, 8, 11, 10, 12, 12, 7, 10, 15, 8, 15, 7, 10, 12, 6, 14, 13, 12, 18, 11, 12, 8, 9, 11, 10, 12, 13, 15, 13, 14, 19, 12, 9, 9, 9, 7, 17, 17, 8, 15, 6, 9, 11, 13, 15, 19, 10, 5, 7, 6, 7, 12, 14, 9, 11, 5, 10, 9, 6, 15, 10, 7, 10, 9, 11, 14, 10, 39, 22, 6, 9, 8, 8, 8, 12, 15, 15, 12, 11, 9, 6, 8, 15, 9, 8, 9, 24, 13, 18, 17, 12, 7, 15, 6, 12, 22, 11, 4, 14, 16, 20, 9, 15, 12, 12, 9, 6], "policy_random_reward": [-2.0, -2.0, 2.0, 1.0, 1.0, -1.0, 1.0, -2.0, 2.0, 1.0, -1.0, 1.0, -1.0, -2.0, 1.0, -1.0, 1.0, -1.0, -2.0, -1.0, 1.0, -2.0, 2.0, 2.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -2.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 2.0, -1.0, 1.0, -2.0, -1.0, 1.0, -2.0, -2.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, -2.0, 2.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, 2.0, -2.0, -2.0, 2.0, -2.0, 2.0, -2.0, 2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 2.0, -2.0, 2.0, 1.0, 1.0, -1.0, 2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -2.0, 1.0, 2.0, -2.0, 1.0, -2.0, -2.0, -2.0, -2.0, -1.0, 2.0, -2.0, -2.0, -2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -1.0, -2.0, 2.0, 2.0, 2.0, 1.0, -1.0, -2.0, -2.0, -2.0, 2.0, -2.0, 1.0, 2.0, -2.0, -1.0, 1.0, -1.0, -2.0, 2.0, -2.0, -1.0, 1.0, 2.0, -2.0, -1.0, -2.0, 2.0, 1.0, -1.0, 1.0, -1.0, -2.0, -2.0, 1.0, -2.0, 1.0, 2.0, -2.0, -1.0, 1.0, -1.0, 1.0, -2.0, -2.0, 2.0, -1.0, 1.0, -1.0, -2.0, 2.0, -2.0, -2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0], "policy_player_2_reward": [2.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, -2.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, 1.0, -2.0, 2.0, -2.0, -2.0, -1.0, 1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -2.0, 1.0, 1.0, -2.0, 1.0, -1.0, 2.0, 2.0, 2.0, 2.0, -1.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, 2.0, 2.0, 2.0, -2.0, -1.0, 2.0, 2.0, 2.0, 2.0, -2.0, 1.0, 2.0, -1.0, 1.0, 1.0, -2.0, -1.0, 1.0, 2.0, 1.0, 1.0, 2.0, -2.0, 2.0, -2.0, 1.0, -1.0, 1.0, 2.0, 2.0, -1.0, -1.0, -1.0, 2.0, -1.0, -1.0, -2.0, 1.0, -2.0, -2.0, 2.0, 1.0, 1.0, 2.0, -1.0, -2.0], "policy_player_1_reward": [-1.0, 1.0, 2.0, 1.0, -2.0, -2.0, -1.0, 2.0, 1.0, -2.0, 1.0, -1.0, 2.0, 2.0, 2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -1.0, -1.0, 2.0, 2.0, 2.0, 2.0, 2.0, -2.0, 2.0, -2.0, 2.0, -1.0, -1.0, -1.0, -2.0, 2.0, -1.0, -2.0, 2.0, 1.0, 1.0, -1.0, -2.0, -1.0, 2.0, -1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, -2.0, -1.0, -1.0, 1.0, -2.0, 1.0, 1.0, 1.0, 1.0, 2.0, -2.0, 1.0, -2.0, 2.0, 1.0, -2.0, -2.0, 2.0, -1.0, -1.0, -1.0, 2.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, -1.0, 1.0, 1.0, -1.0, 2.0, -2.0, -2.0, 1.0, 1.0, -2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, -2.0, -2.0, 1.0, -1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8034351282252044, "mean_inference_ms": 1.1324076710090774, "mean_action_processing_ms": 0.1715296936522637, "mean_env_wait_ms": 0.11053251104652687, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.01302886212992872, "ViewRequirementAgentConnector_ms": 0.2444185762323885}, "player_1_winrate": 0.5480769230769231, "player_2_winrate": 0.5471698113207547, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {}, "episode_media": {}, "info": {"learner": {"player_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7374349556717217, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7617148574660806, "policy_loss": -0.029978295202896584, "vf_loss": 1.7882161201215259, "vf_explained_var": 0.14816009998321533, "kl": 0.017385159800560393, "entropy": 1.3952375318489822, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 123.0, "num_grad_updates_lifetime": 1785.5, "diff_num_grad_updates_vs_sampler_policy": 254.5}, "player_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4608600054846868, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.793947799735599, "policy_loss": -0.03907149196188483, "vf_loss": 1.8292967624134489, "vf_explained_var": 0.1271991735034519, "kl": 0.0186126494309633, "entropy": 1.4493544358677335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.26666666666667, "num_grad_updates_lifetime": 1635.5, "diff_num_grad_updates_vs_sampler_policy": 224.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 15998, "num_agent_steps_trained": 15998}, "sampler_results": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 10.571052631578947, "episode_media": {}, "episodes_this_iter": 380, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.007894736842105263, "player_2": -0.007894736842105263}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [13, 8, 17, 13, 8, 12, 12, 11, 14, 9, 11, 11, 13, 6, 11, 7, 12, 12, 11, 6, 10, 12, 9, 5, 11, 10, 6, 13, 8, 7, 18, 9, 20, 13, 7, 18, 14, 8, 9, 6, 11, 11, 9, 12, 9, 17, 15, 10, 7, 16, 14, 6, 16, 9, 9, 6, 11, 5, 9, 16, 11, 8, 5, 7, 11, 11, 5, 13, 10, 10, 18, 8, 23, 14, 6, 12, 11, 7, 6, 9, 15, 15, 7, 13, 11, 14, 14, 12, 6, 8, 7, 8, 10, 14, 5, 11, 14, 12, 6, 23, 13, 12, 15, 7, 8, 13, 10, 9, 12, 14, 7, 11, 16, 10, 10, 8, 18, 9, 13, 6, 8, 16, 13, 6, 12, 11, 13, 8, 14, 5, 9, 15, 8, 13, 11, 9, 12, 6, 8, 8, 8, 9, 6, 9, 5, 7, 6, 11, 13, 13, 10, 5, 6, 6, 10, 11, 15, 5, 10, 5, 9, 11, 12, 12, 13, 12, 8, 6, 12, 12, 10, 9, 6, 10, 6, 17, 10, 15, 12, 6, 9, 8, 5, 7, 9, 11, 11, 10, 7, 11, 13, 8, 16, 17, 6, 9, 10, 12, 12, 4, 11, 15, 6, 15, 16, 10, 6, 6, 10, 5, 6, 14, 11, 12, 20, 11, 13, 7, 12, 8, 18, 13, 9, 18, 8, 6, 10, 13, 14, 14, 11, 9, 10, 8, 13, 9, 20, 10, 12, 6, 10, 10, 9, 6, 10, 8, 14, 11, 9, 6, 11, 12, 13, 19, 12, 8, 12, 13, 9, 13, 6, 11, 6, 16, 14, 16, 13, 10, 6, 6, 15, 6, 9, 13, 13, 10, 10, 15, 5, 11, 14, 12, 20, 7, 11, 12, 9, 7, 11, 10, 14, 11, 11, 14, 9, 9, 16, 7, 9, 12, 19, 9, 7, 11, 12, 6, 8, 12, 11, 6, 12, 8, 17, 6, 12, 20, 5, 11, 8, 13, 15, 12, 17, 9, 8, 10, 6, 4, 15, 10, 17, 14, 16, 8, 6, 17, 6, 5, 10, 11, 6, 13, 8, 10, 7, 10, 19, 8, 7, 13, 6, 7, 8, 14, 11, 7, 5, 19, 7, 10, 6, 14, 7, 11, 6, 8, 25, 14, 13, 7, 11, 11, 9, 10, 8, 11, 6, 19, 14, 10], "policy_player_1_reward": [1.0, -1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 2.0, 2.0, -1.0, -1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 1.0, 2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, -1.0, -2.0, -1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -1.0, 1.0, -2.0, 1.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, -2.0, -1.0, -1.0, -1.0, 2.0, 1.0, -1.0, 2.0, -1.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -1.0, -2.0, 1.0, 1.0, 2.0, 1.0, -2.0, 2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, -2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, -1.0, 2.0, 1.0, -2.0, 1.0, -1.0, 2.0, -1.0, 2.0, 2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 1.0, 2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 1.0, -1.0, -2.0, -2.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, -1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, 1.0, 2.0, -1.0, 2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, -2.0, 2.0, -1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, -1.0, 1.0, -1.0, 2.0, -2.0, 2.0, -2.0, -2.0, 1.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -2.0, -2.0, 2.0, -1.0, -2.0, -2.0, -1.0, -2.0, -2.0, -1.0, 2.0, 1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, 2.0, -2.0, -2.0, 1.0, -2.0, -2.0, -2.0, -1.0, 2.0, -2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 2.0, 2.0, 2.0, -2.0, -2.0, -2.0, -2.0, 1.0, 1.0, -1.0], "policy_player_2_reward": [-1.0, 1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -2.0, -2.0, 1.0, 1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -1.0, -2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, 1.0, 2.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 1.0, -1.0, 2.0, -1.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, 2.0, 1.0, 1.0, 1.0, -2.0, -1.0, 1.0, -2.0, 1.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 1.0, 2.0, -1.0, -1.0, -2.0, -1.0, 2.0, -2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, 1.0, -2.0, -1.0, 2.0, -1.0, 1.0, -2.0, 1.0, -2.0, -2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, -1.0, -2.0, 1.0, -1.0, 1.0, 2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -1.0, 1.0, 2.0, 2.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, 1.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, -1.0, -2.0, 1.0, -2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, 2.0, -2.0, 1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, 1.0, -1.0, 1.0, -2.0, 2.0, -2.0, 2.0, 2.0, -1.0, -1.0, -1.0, 1.0, -2.0, 2.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 2.0, -2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, -2.0, -1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -2.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, -2.0, 2.0, 2.0, -1.0, 2.0, 2.0, 2.0, 1.0, -2.0, 2.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -2.0, -2.0, -2.0, 2.0, 2.0, 2.0, 2.0, -1.0, -1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7115112069535788, "mean_inference_ms": 1.9247020691222905, "mean_action_processing_ms": 0.18753667225888304, "mean_env_wait_ms": 0.1248656366775723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.015881688971268505, "ViewRequirementAgentConnector_ms": 0.22601554268284849}}, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 10.571052631578947, "episodes_this_iter": 380, "policy_reward_min": {"player_1": -2.0, "player_2": -2.0}, "policy_reward_max": {"player_1": 2.0, "player_2": 2.0}, "policy_reward_mean": {"player_1": 0.007894736842105263, "player_2": -0.007894736842105263}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [13, 8, 17, 13, 8, 12, 12, 11, 14, 9, 11, 11, 13, 6, 11, 7, 12, 12, 11, 6, 10, 12, 9, 5, 11, 10, 6, 13, 8, 7, 18, 9, 20, 13, 7, 18, 14, 8, 9, 6, 11, 11, 9, 12, 9, 17, 15, 10, 7, 16, 14, 6, 16, 9, 9, 6, 11, 5, 9, 16, 11, 8, 5, 7, 11, 11, 5, 13, 10, 10, 18, 8, 23, 14, 6, 12, 11, 7, 6, 9, 15, 15, 7, 13, 11, 14, 14, 12, 6, 8, 7, 8, 10, 14, 5, 11, 14, 12, 6, 23, 13, 12, 15, 7, 8, 13, 10, 9, 12, 14, 7, 11, 16, 10, 10, 8, 18, 9, 13, 6, 8, 16, 13, 6, 12, 11, 13, 8, 14, 5, 9, 15, 8, 13, 11, 9, 12, 6, 8, 8, 8, 9, 6, 9, 5, 7, 6, 11, 13, 13, 10, 5, 6, 6, 10, 11, 15, 5, 10, 5, 9, 11, 12, 12, 13, 12, 8, 6, 12, 12, 10, 9, 6, 10, 6, 17, 10, 15, 12, 6, 9, 8, 5, 7, 9, 11, 11, 10, 7, 11, 13, 8, 16, 17, 6, 9, 10, 12, 12, 4, 11, 15, 6, 15, 16, 10, 6, 6, 10, 5, 6, 14, 11, 12, 20, 11, 13, 7, 12, 8, 18, 13, 9, 18, 8, 6, 10, 13, 14, 14, 11, 9, 10, 8, 13, 9, 20, 10, 12, 6, 10, 10, 9, 6, 10, 8, 14, 11, 9, 6, 11, 12, 13, 19, 12, 8, 12, 13, 9, 13, 6, 11, 6, 16, 14, 16, 13, 10, 6, 6, 15, 6, 9, 13, 13, 10, 10, 15, 5, 11, 14, 12, 20, 7, 11, 12, 9, 7, 11, 10, 14, 11, 11, 14, 9, 9, 16, 7, 9, 12, 19, 9, 7, 11, 12, 6, 8, 12, 11, 6, 12, 8, 17, 6, 12, 20, 5, 11, 8, 13, 15, 12, 17, 9, 8, 10, 6, 4, 15, 10, 17, 14, 16, 8, 6, 17, 6, 5, 10, 11, 6, 13, 8, 10, 7, 10, 19, 8, 7, 13, 6, 7, 8, 14, 11, 7, 5, 19, 7, 10, 6, 14, 7, 11, 6, 8, 25, 14, 13, 7, 11, 11, 9, 10, 8, 11, 6, 19, 14, 10], "policy_player_1_reward": [1.0, -1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, 1.0, -2.0, 1.0, -2.0, -1.0, 2.0, 2.0, -2.0, -1.0, -1.0, 2.0, 2.0, -1.0, 2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 2.0, 2.0, -1.0, -1.0, -1.0, 2.0, 1.0, 2.0, -2.0, 1.0, 1.0, 1.0, -1.0, -1.0, 2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 1.0, 2.0, 1.0, -2.0, 1.0, -1.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, -2.0, -1.0, 1.0, -1.0, 2.0, -2.0, 1.0, -1.0, -2.0, -1.0, -2.0, 2.0, 2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -1.0, 1.0, -2.0, 1.0, 1.0, 1.0, 1.0, -2.0, 2.0, 2.0, -2.0, -1.0, -1.0, -1.0, 2.0, 1.0, -1.0, 2.0, -1.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, -2.0, 2.0, -1.0, -2.0, 1.0, 1.0, 2.0, 1.0, -2.0, 2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 1.0, 1.0, -1.0, -2.0, -2.0, -2.0, -2.0, 1.0, 1.0, 2.0, 2.0, 2.0, -1.0, 2.0, -1.0, 1.0, -1.0, -1.0, -2.0, -2.0, -1.0, -1.0, 2.0, 1.0, 2.0, -1.0, 2.0, 1.0, -2.0, 1.0, -1.0, 2.0, -1.0, 2.0, 2.0, 2.0, 2.0, 1.0, -2.0, 1.0, -2.0, 1.0, -2.0, -1.0, 1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, 1.0, 2.0, -1.0, 1.0, -1.0, -2.0, 1.0, -2.0, -2.0, 2.0, -2.0, 1.0, -1.0, -2.0, -2.0, 1.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, -1.0, 2.0, 2.0, 2.0, 1.0, 2.0, -1.0, 1.0, 2.0, -1.0, 2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -1.0, 1.0, -2.0, -2.0, -1.0, -2.0, 1.0, 1.0, -2.0, 2.0, -1.0, 1.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, -1.0, 1.0, -1.0, 2.0, -2.0, 2.0, -2.0, -2.0, 1.0, 1.0, 1.0, -1.0, 2.0, -2.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, 1.0, -1.0, 1.0, -2.0, -2.0, 2.0, -1.0, -2.0, -2.0, -1.0, -2.0, -2.0, -1.0, 2.0, 1.0, 2.0, -1.0, -1.0, -2.0, 2.0, 2.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -2.0, -2.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, 2.0, -2.0, 1.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, 2.0, -2.0, -2.0, 1.0, -2.0, -2.0, -2.0, -1.0, 2.0, -2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, -2.0, -1.0, -1.0, 2.0, -1.0, 2.0, 2.0, 2.0, -2.0, -2.0, -2.0, -2.0, 1.0, 1.0, -1.0], "policy_player_2_reward": [-1.0, 1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -1.0, 2.0, -1.0, -1.0, 2.0, -1.0, 2.0, 1.0, -2.0, -2.0, 2.0, 1.0, 1.0, -2.0, -2.0, 1.0, -2.0, -2.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -2.0, -2.0, 1.0, 1.0, 1.0, -2.0, -1.0, -2.0, 2.0, -1.0, -1.0, -1.0, 1.0, 1.0, -2.0, 1.0, 1.0, 2.0, 2.0, -1.0, -1.0, -2.0, -1.0, 2.0, -1.0, 1.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, 2.0, 1.0, -1.0, 1.0, -2.0, 2.0, -1.0, 1.0, 2.0, 1.0, 2.0, -2.0, -2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -1.0, -2.0, -1.0, 1.0, -1.0, 2.0, -1.0, -1.0, -1.0, -1.0, 2.0, -2.0, -2.0, 2.0, 1.0, 1.0, 1.0, -2.0, -1.0, 1.0, -2.0, 1.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, -1.0, 2.0, -2.0, 1.0, 2.0, -1.0, -1.0, -2.0, -1.0, 2.0, -2.0, 2.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -1.0, -1.0, 1.0, 2.0, 2.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, -2.0, 1.0, -2.0, 1.0, -1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, -2.0, -1.0, -2.0, 1.0, -2.0, -1.0, 2.0, -1.0, 1.0, -2.0, 1.0, -2.0, -2.0, -2.0, -2.0, -1.0, 2.0, -1.0, 2.0, -1.0, 2.0, 1.0, -1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 1.0, -2.0, 1.0, -1.0, -2.0, 1.0, -1.0, 1.0, 2.0, -1.0, 2.0, 2.0, -2.0, 2.0, -1.0, 1.0, 2.0, 2.0, -1.0, 2.0, 1.0, 2.0, 1.0, -1.0, -1.0, 1.0, -2.0, -2.0, -2.0, -1.0, -2.0, 1.0, -1.0, -2.0, 1.0, -2.0, -2.0, -2.0, 1.0, 2.0, 1.0, -2.0, -2.0, 2.0, 2.0, -2.0, -2.0, 2.0, 1.0, -1.0, 2.0, 2.0, 1.0, 2.0, -1.0, -1.0, 2.0, -2.0, 1.0, -1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 1.0, 1.0, 1.0, -1.0, 1.0, -2.0, 2.0, -2.0, 2.0, 2.0, -1.0, -1.0, -1.0, 1.0, -2.0, 2.0, -2.0, 1.0, -1.0, 1.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, -1.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, 1.0, 2.0, -1.0, 1.0, -1.0, 2.0, 2.0, -2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, -2.0, -1.0, -2.0, 1.0, 1.0, 2.0, -2.0, -2.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, -2.0, -1.0, -2.0, -1.0, 1.0, 1.0, 2.0, 2.0, -1.0, -2.0, -2.0, 2.0, -1.0, 2.0, -1.0, -2.0, -1.0, 2.0, 2.0, -2.0, 2.0, 2.0, -1.0, 2.0, 2.0, 2.0, 1.0, -2.0, 2.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, -1.0, -2.0, 2.0, 1.0, 1.0, -2.0, 1.0, -2.0, -2.0, -2.0, 2.0, 2.0, 2.0, 2.0, -1.0, -1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7115112069535788, "mean_inference_ms": 1.9247020691222905, "mean_action_processing_ms": 0.18753667225888304, "mean_env_wait_ms": 0.1248656366775723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"StateBufferConnector_ms": 0.015881688971268505, "ViewRequirementAgentConnector_ms": 0.22601554268284849}, "num_healthy_workers": 2, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15998, "num_agent_steps_trained": 15998, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.10045332249044, "num_env_steps_trained_throughput_per_sec": 210.10045332249044, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 15998, "timers": {"training_iteration_time_ms": 21454.323, "sample_time_ms": 5980.3, "learn_time_ms": 15466.445, "learn_throughput": 258.624, "synch_weights_time_ms": 6.799}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 15998, "num_agent_steps_trained": 15998}, "done": false, "episodes_total": 1301, "training_iteration": 4, "trial_id": "d977f_00000", "date": "2024-03-27_14-49-25", "timestamp": 1711550965, "time_this_iter_s": 22.357417821884155, "time_total_s": 102.34644937515259, "pid": 8992, "hostname": "DESKTOP-RNN7NJG", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "Coup", "env_config": {"action_space": "Discrete(11)", "observation_space": "MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11])"}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "_env_to_module_connector": null, "_module_to_env_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": true, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "am_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x00000217B5753400>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 1, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"multiagent": {"policy_mapping_fn": "<function policy_mapping_fn at 0x00000217B5753490>"}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 2, "custom_async_evaluation_function": null, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": true, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"player_1": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "player_2": [null, "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}], "random": ["<class '__main__.RandomPolicyActionMask'>", "Dict('action_mask': MultiBinary(11), 'observations': MultiDiscrete([ 5  5  2  2 14  6  6 14 11 11 11 11 11 11 11 11 11 11]))", "Discrete(11)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function custom_eval_function at 0x00000217B5673B50>", "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 2}, "time_since_restore": 102.34644937515259, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 11.556249999999999, "ram_util_percent": 93.975}}
